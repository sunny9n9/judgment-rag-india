{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7e105b6086b34993bb6e876c43df57d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63e4b7f2df3741539bc5e0351abb6f35",
              "IPY_MODEL_4a033513316e4bf7b71dbaddf348ea8a",
              "IPY_MODEL_21e26ed58ad04bb5b7cb19f22687153b"
            ],
            "layout": "IPY_MODEL_30fa27c83e3d4947bdaa500775028adb"
          }
        },
        "63e4b7f2df3741539bc5e0351abb6f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36f1d5b2105148dbb10f86421ced492f",
            "placeholder": "​",
            "style": "IPY_MODEL_2a6574d0cffd41df94960582fb7e59ad",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4a033513316e4bf7b71dbaddf348ea8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b21ba6fe1a54bbeac9cddd11b440aff",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d837a00b03154095bcd2a4528d9a8585",
            "value": 3
          }
        },
        "21e26ed58ad04bb5b7cb19f22687153b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e87a642740cf4ee69394ac399ed642f6",
            "placeholder": "​",
            "style": "IPY_MODEL_4e2605a16f924bd68a7c166cff6d5f20",
            "value": " 3/3 [01:43&lt;00:00, 32.27s/it]"
          }
        },
        "30fa27c83e3d4947bdaa500775028adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36f1d5b2105148dbb10f86421ced492f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a6574d0cffd41df94960582fb7e59ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b21ba6fe1a54bbeac9cddd11b440aff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d837a00b03154095bcd2a4528d9a8585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e87a642740cf4ee69394ac399ed642f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e2605a16f924bd68a7c166cff6d5f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned in anotehr file, i cannot upload my faiss index to drive\n",
        "\n",
        "FAISS indexes contain native C++ state and cannot be reliably serialized with pickle. Indexes hebce, are rebuilt from saved embeddings instead of being loaded from disk.\n"
      ],
      "metadata": {
        "id": "4S7uZtFVMcLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "PATH_TO_CHUNKS = '/content/drive/MyDrive/colab_stuff/court_hearings_rag/chunk_text.pkl'\n",
        "with open(PATH_TO_CHUNKS, 'rb') as f:\n",
        "    metadata = pickle.load(f)"
      ],
      "metadata": {
        "id": "OIFapyRIGSQx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "embedding_bns = np.load('/content/drive/MyDrive/colab_stuff/court_hearings_rag/bns_embed.npy')\n",
        "embedding_apex = np.load('/content/drive/MyDrive/colab_stuff/court_hearings_rag/apex_embed.npy')\n",
        "embedding_high = np.load('/content/drive/MyDrive/colab_stuff/court_hearings_rag/high_embed.npy')"
      ],
      "metadata": {
        "id": "xxziEtAcM0Au"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "again reminder, faiss cpu us used because model is going to be too big to leave any space in GPU. Either way, faiss is quite old thing, it was designed around cpu, its fine, its fast, its default so much so i need to manually make gpu element and copy index there faiss.index_cpu_to_gpu()"
      ],
      "metadata": {
        "id": "v92smeFr0uNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "import faiss\n",
        "\n",
        "dim = embedding_bns.shape[1]\n",
        "\n",
        "index_bns = faiss.IndexFlatIP(dim)\n",
        "index_apex = faiss.IndexFlatIP(dim)\n",
        "index_high = faiss.IndexFlatIP(dim)\n",
        "\n",
        "index_bns.add(embedding_bns)\n",
        "index_apex.add(embedding_apex)\n",
        "index_high.add(embedding_high)"
      ],
      "metadata": {
        "id": "ucLt1r2ylKN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3fa187-728f-427a-ec96-3240000c5c1b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validating sizes just confirming its same accross file\n",
        "print(f'size of bns metadata :: {len(metadata[0])} size of index :: {len(embedding_bns)}')\n",
        "print(f'size of apex metadata :: {len(metadata[1])} size of index :: {len(embedding_apex)}')\n",
        "print(f'size of high metadata :: {len(metadata[2])} size of index :: {len(embedding_high)}')"
      ],
      "metadata": {
        "id": "PB_uIlSmPmTl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e6938ac-a706-4b5f-9bc5-97ce3569cc19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of bns metadata :: 471 size of index :: 471\n",
            "size of apex metadata :: 770935 size of index :: 770935\n",
            "size of high metadata :: 441735 size of index :: 441735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentence_transformers\n",
        "model_faiss = sentence_transformers.SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "def search_info(query, model, metadata, top_k=5):\n",
        "    # first use the same sentance embedding model to make query database compatible\n",
        "    query_vector = model.encode(query, normalize_embeddings=True, convert_to_numpy=True)\n",
        "\n",
        "    sim_1, idx_1 = index_bns.search(query_vector, top_k)\n",
        "    sim_2, idx_2 = index_apex.search(query_vector, top_k)\n",
        "    sim_3, idx_3 = index_high.search(query_vector, top_k )\n",
        "\n",
        "    bns, apex, high = metadata\n",
        "    print(len(query))\n",
        "    for q in range(len(query)):\n",
        "        for i in range(top_k):\n",
        "            print(f'{i+1}th most similar to query in bns with similarity :: {sim_1[q][i]} is :: \\n{bns[idx_1[q][i]]}')\n",
        "            print(f'{i+1}th most similar to query in apex with similarity :: {sim_2[q][i]} is :: \\n{apex[idx_2[q][i]]}')\n",
        "            print(f'{i+1}th most similar to query in high with similarity :: {sim_3[q][i]} is :: \\n{high[idx_3[q][i]]}')\n",
        "\n",
        "query = [\n",
        "    \"What constitutes giving false evidence in a judicial proceeding under criminal law?\",\n",
        "    \"What is the punishment for using fabricated or false evidence in a criminal case?\"\n",
        "  ]\n",
        "search_info(query, model_faiss, metadata, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5NpGcmeHlK9n",
        "outputId": "6fd1e37b-c70d-410b-d7c0-f2ffdd8f69d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "1th most similar to query in bns with similarity :: 0.6652504205703735 is :: \n",
            "{'chunk_id': 'BNS_BNS_228_0', 'chunk_text': 'Whoever causes any circumstance to exist or makes any false entry in any book or record, or electronic record or makes any document or electronic record containing a false statement, intending that such circumstance, false entry or false statement may appear in evidence in a judicial proceeding, or in a proceeding taken by law before a public servant as such, or before an arbitrator, and that such circumstance, false entry or false statement, so appearing in evidence, may cause any person who in such proceeding is to form an opinion upon the evidence, to entertain an erroneous opinion touching any point material to the result of such proceeding is said \"to fabricate false evidence\".\\nIllustrations.\\n(a) A puts jewels into a box belonging to Z, with the intention that they may be found in that box, and that this circumstance may cause Z to be convicted of theft. A has fabricated false evidence.\\n(b) A makes a false entry in his shop-book for the purpose of using it as corroborative evidence in a Court. A has fabricated false evidence.\\n(c) A, with the intention of causing Z to be convicted of a criminal conspiracy, writes a letter in imitation of Z\\'s handwriting, purporting to be addressed to an accomplice in such criminal conspiracy, and puts the letter in a place which he knows that the officers of the police are likely to search. A has fabricated false evidence.', 'parent_id': 'BNS_228', 'source': 'BNS'}\n",
            "1th most similar to query in apex with similarity :: 0.733629584312439 is :: \n",
            "{'chunk_id': 'Supreme Court_23569_12', 'chunk_text': 'It any book or record, or electronic was not a judicial proceeding and the record or makes any document or petitioner has neither fabricated false electronic record containing a false evidence nor made any false entry in statement, intending that such any book, record or electronic data.\\ncircumstance, false entry or false Mere exercising of administrative statement may appear in evidence in power cannot be construed as a judicial proceeding, or in a fabricating false evidence. proceeding taken by law before a public servant as such, or before an arbitrator, and that such circumstance, false entry or false statement, so appearing in evidence, may cause any person who in such proceeding is to form an opinion upon the evidence, to entertain an erroneous opinion touching any point material to the result of such proceeding, is said “to fabricate false evidence”. 193.\\nPunishment for false Since there was no ‘false evidence’, evidence.\\n– Whoever intentionally therefore the possibility of gives false evidence in any stage of a punishment accruing to false judicial proceeding, or fabricates false evidence is ruled out.\\nevidence for the purpose of being used in any stage of a judicial proceeding, shall be punished with imprisonment of either description for a term which may extend to seven years, an shall also be liable to fine, and whoever intentionally gives or fabricates false evidence in any other case, shall be punished with imprisonment of either description for a term which may extend to three years, and shall also be liable. 203.', 'parent_id': 23569, 'source': 'Supreme Court'}\n",
            "1th most similar to query in high with similarity :: 0.7120130062103271 is :: \n",
            "{'chunk_id': 'Courts_COURTS_6251_11', 'chunk_text': '7.Learned Senior counsel for the petitioner would submit that a reading of the charge sheet would show that in effect what the petitioner is accused of is an offence under Section 192 I.P.C. 8.Section 192 I.P.C. reads as follows: \"Fabricating false evidence. - Whoever causes any circumstance to exist or makes any false entry in any book or record, or electronic record or makes any document or electronic record containing a false statement, intending that such circumstance, false entry or false statement may appear in evidence in a judicial proceeding, or in a proceeding taken by law before a public servant as such, or before an arbitrator, and that such circumstance, false entry or false statement, so appearing in evidence, may cause any person who in such proceeding is to form an opinion upon the evidence, to entertain an erroneous opinion touching any point material to the result of such proceeding, is said \"to fabricate false evidence\".\"', 'parent_id': 'COURTS_6251', 'source': 'Courts'}\n",
            "2th most similar to query in bns with similarity :: 0.6567000150680542 is :: \n",
            "{'chunk_id': 'BNS_BNS_229_0', 'chunk_text': '(1) Whoever intentionally gives false evidence in any stage of a judicial proceeding, or fabricates false evidence for the purpose of being used in any stage of a judicial proceeding, shall be punished with imprisonment of either description for a term which may extend to seven years, and shall also be liable to fine which may extend to ten thousand rupees.\\n(2) Whoever intentionally gives or fabricates false evidence in any case other than that referred to in sub-section (1), shall be punished with imprisonment of either description for a term which may extend to three years, and shall also be liable to fine which may extend to five thousand rupees.\\nExplanation 1.—A trial before a Court-martial is a judicial proceeding.\\nExplanation 2.—An investigation directed by law preliminary to a proceeding before a Court, is a stage of a judicial proceeding, though that investigation may not take place before a Court.\\nIllustration.\\nA, in an enquiry before a Magistrate for the purpose of ascertaining whether Z ought to be committed for trial, makes on oath a statement which he knows to be false. As this enquiry is a stage of a judicial proceeding, A has given false evidence.\\nExplanation 3.—An investigation directed by a Court according to law, and conducted under the authority of a Court, is a stage of a judicial proceeding, though that investigation may not take place before a Court.\\nIllustration.', 'parent_id': 'BNS_229', 'source': 'BNS'}\n",
            "2th most similar to query in apex with similarity :: 0.7200062274932861 is :: \n",
            "{'chunk_id': 'Supreme Court_23723_8', 'chunk_text': 'and there must be prima facie case of deliberate falsehood on the matter of substance and the Court should be satisfied that there is reasonable foundation for the charge”.\\nThe assessment made by the High Court, as extracted in the paragraph hereinabove, in our considered view, does not satisfy the parameters and requirements as laid down by this Court. 13.\\nRecently, this Court in Amarsang Nathaji v.\\nHardik Harshadbhai Patel and Others4 summed up the legal position as under: “6.\\nThe mere fact that a person has made a contradictory statement in a judicial proceeding is not by itself always sufficient to justify a prosecution under Sections 199 and 200 of the Penal Code, 1860 (45 of 1860) (hereinafter referred to as “IPC”); but it must be shown that the defendant has intentionally given a false statement at any stage of the judicial proceedings or fabricated false evidence for the purpose of using the same at any stage of the judicial proceedings.\\nEven after the above position has emerged also, still the court has to form an opinion that it is expedient in the interests of justice to initiate an inquiry into the offences of false evidence and offences against public justice and more specifically referred to in Section 340(1) CrPC, having regard to the overall factual matrix as well as the probable consequences of such a prosecution.\\n(See K.T.M.S.\\nMohd.\\nv.\\nUnion of India).', 'parent_id': 23723, 'source': 'Supreme Court'}\n",
            "2th most similar to query in high with similarity :: 0.6926910877227783 is :: \n",
            "{'chunk_id': 'Courts_COURTS_5402_45', 'chunk_text': 'Court, any basic infirmities appearing in the case and so on. This however does not mean that the Judge should make a roving enquiry into the pros and cons of the matter and weigh the evidence as if he was conducting a trial (Union of India v. Prafulla Kumar AIR 1979 SC 366).\\nIt seems well settled that at the Ss.227-228 stage i.e., stage of framing the charge, the Court is required to evaluate the material and documents on record with a view to finding out if the facts emerging therefrom taken at their face value disclose the existence of all the ingredients constituting the alleged offence. The Court may for this limited purpose sift the evidence as it cannot be expected even at that initial stage to accept all that the prosecution states as gospel truth even if it is opposed to common sense or the broad probabilities of the case (See. Niranjan Singh Karam Singh Punjabi, Advocate v. Jitendra Bhimraj Bijja AIR 1990 SC 1962).', 'parent_id': 'COURTS_5402', 'source': 'Courts'}\n",
            "1th most similar to query in bns with similarity :: 0.778023898601532 is :: \n",
            "{'chunk_id': 'BNS_BNS_233_0', 'chunk_text': 'Whoever corruptly uses or attempts to use as true or genuine evidence any evidence which he knows to be false or fabricated, shall be punished in the same manner as if he gave or fabricated false evidence.', 'parent_id': 'BNS_233', 'source': 'BNS'}\n",
            "1th most similar to query in apex with similarity :: 0.7792315483093262 is :: \n",
            "{'chunk_id': 'Supreme Court_10587_12', 'chunk_text': 'Punishment for false evidence.-Whoever intentionally gives false evidence in any stage of a judicial proceeding, or fabricates false evidence for the purpose of being used in any stage of a judicial proceeding, shall be punished with imprisonment of either description for a term which may extend to seven years, and shall also be liable to fine; and whoever intentionally gives or fabricates false evidence in any other case, shall be punished with imprisonment of either description for a term which extend to three years, and shall also be liable to fine. Explanation.-........................................\\n\"196.\\nUsing evidence known to be false.-Whoever corruptly uses or attempts to use as true or genuine evidence any evidence which he knows to be false or fabricated, shall be punished in the same manner as if he gave or fabricated false evidence.\\' At the outset it has to be stated that there is no provision in law which provides that a prosecution for the offences in question cannot be launched until reassessment proceedings initiated against the assessee are completed.\\nSection 279 of the Act provides that a person shall not be proceeded against for an offence punishable under section 276C or section 277 of the Act except at the instance of the Commissioner.', 'parent_id': 10587, 'source': 'Supreme Court'}\n",
            "1th most similar to query in high with similarity :: 0.6160721182823181 is :: \n",
            "{'chunk_id': 'Courts_COURTS_6212_26', 'chunk_text': '17.30. When the incriminating circumstances, arising out of the testimonies of the prosecution witnesses, were put to the appellants/accused 1 to 6 to explain as contemplated under Section 313(i)(b) Cr.P.C., they had replied that this case was foisted against them. Even though they had claimed that they were going to examine witnesses on their side, nobody was examined and no documentary evidence was also adduced on their behalf.\\n17.31. On evaluating the evidences both oral and documentary, the learned Trial Judge has found the appellants/accused 1-6 guilty, convicted and sentenced as aforestated.\\n18. \"To prove that an accused is a murderer is one of the most difficult tasks faced by a criminal lawyer. The mode of proof may take diverse forms, it may be by both direct evidence and circumstantial evidence. It may be through dying declaration, confession, evidence of near relations and so on. One or more modes of proof may be telescoped in a particular case. It may be borne in mind that burden of proving the case initially is on the prosecution which must prove it beyond reasonable doubt.\"', 'parent_id': 'COURTS_6212', 'source': 'Courts'}\n",
            "2th most similar to query in bns with similarity :: 0.6893277764320374 is :: \n",
            "{'chunk_id': 'BNS_BNS_246_0', 'chunk_text': 'Whoever fraudulently or dishonestly, or with intent to injure or annoy any person, makes in a Court any claim which he knows to be false, shall be punished with imprisonment of either description for a term which may extend to two years, and shall also be liable to fine.', 'parent_id': 'BNS_246', 'source': 'BNS'}\n",
            "2th most similar to query in apex with similarity :: 0.7203802466392517 is :: \n",
            "{'chunk_id': 'Supreme Court_24433_19', 'chunk_text': 'Fabricating false evidence.—Whoever causes any circumstance to exist or makes any false entry in any book or record, or electronic record or makes any document or electronic record containing a false statement, intending that such circumstance, false entry or false statement may appear in evidence in a judicial proceeding, or in a proceeding taken by law before a public servant as such, or before an arbitrator, and that such circumstance, false entry or false statement, so appearing in evidence, may cause any person who in such proceeding is to form an opinion upon the evidence, to entertain an erroneous opinion touching any point material to the result of such proceeding is said “to fabricate false evidence”. 193.\\nPunishment for false evidence.—Whoever intentionally gives false evidence in any of a judicial proceeding, or fabricates false evidence for the purpose of being used in any stage of a judicial proceeding, shall be punished with imprisonment of either description for a term which may extend to seven years, and shall also be liable to fine; and whoever intentionally gives or fabricates false evidence in any other case, shall be punished with imprisonment of either description for a term which may extend to three years, and shall also be liable to fine.', 'parent_id': 24433, 'source': 'Supreme Court'}\n",
            "2th most similar to query in high with similarity :: 0.6082550287246704 is :: \n",
            "{'chunk_id': 'Courts_COURTS_5989_5', 'chunk_text': \"The learned trial Judge framed charge against the accused at Ex.1 for the commission of offences punishable under Sections 302, 435, 404 and 201 IPC to which the accused pleaded not guilty and claimed to be tried and thereupon the prosecution examined witnesses and adduced oral as well as documentary evidence. After the prosecution concluded its oral evidence, the trial Court recorded further statement of the accused under Section 313 of the Code of Criminal Procedure ('Cr.PC' for short) and the accused in his further statement denied generally all the incriminating circumstances put to him by the trial Court and stated that he was falsely implicated in this case and that the cash amount and the cloth seized from him belonged to his father.\\nThe trial Court after appreciating the evidence on record and the submissions made on behalf of both the sides ultimately came to the conclusion that the prosecution has successfully proved the involvement of the accused in the incident. However, the trial Court recorded acquittal of the accused for the offence of murder punishable under Section 302 IPC but recorded his conviction for the offence of culpable homicide not amounting to murder punishable under Section 304 Part I IPC together with other offences punishable under Sections 435, 404 and 201 of IPC and awarded sentence as herein above referred to in this judgment.\", 'parent_id': 'COURTS_5989', 'source': 'Courts'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well it seems colab refuses to believe i have bitsandbytes until i restart kernel, so do that after installing them.\n",
        "\n",
        "BitsAndBytes is responsible for quantization. Model can and does fit in gpu memory even without quantization, but when dealing with large number of documents for retrieval, it gives OOM error.\n",
        "\n",
        "So i quantized for it. Though i since simplified(considerably dumbed down and reduced) total documents retrievals for generation"
      ],
      "metadata": {
        "id": "5wtVoDYl8DwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers bitsandbytes\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "FQII6kk8lRmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well but bear in mind mistral was trained to be helpful to user, to it talks a lot, can't exactly expect it to shut up as we want, even if it does it still talks sometimes cuz query it is going to get are law/crime related so it tries to clear itself by giving some reasoning or advice, so just accept it. Its unexpectedly time consuming to write prompt to get it to do what i want, no more, no less"
      ],
      "metadata": {
        "id": "uZT4ckcf8u28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\" # automatically does cpu/gpu\n",
        ")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    use_fast=True # use rust backend when available\n",
        ")\n",
        "model.eval() # it is all pytorch afterall.\n",
        "print(model.device)"
      ],
      "metadata": {
        "id": "LwHOSheqlePM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95,
          "referenced_widgets": [
            "7e105b6086b34993bb6e876c43df57d4",
            "63e4b7f2df3741539bc5e0351abb6f35",
            "4a033513316e4bf7b71dbaddf348ea8a",
            "21e26ed58ad04bb5b7cb19f22687153b",
            "30fa27c83e3d4947bdaa500775028adb",
            "36f1d5b2105148dbb10f86421ced492f",
            "2a6574d0cffd41df94960582fb7e59ad",
            "5b21ba6fe1a54bbeac9cddd11b440aff",
            "d837a00b03154095bcd2a4528d9a8585",
            "e87a642740cf4ee69394ac399ed642f6",
            "4e2605a16f924bd68a7c166cff6d5f20"
          ]
        },
        "outputId": "b9640e5b-1df8-470f-cba0-a559b23280fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e105b6086b34993bb6e876c43df57d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well i tried with rewriting prompt in an attmpt to improve retrieval, but in most cases the rewritten prompt ends up getting even worse Similarity score than if i sent user query to faiss directly. So that is what i am gonna do, no rewriting.\n",
        "\n",
        "The reason for this, what i believe, is mistral trying to be overly helpful. It rewrites the prompt but the rewritten one(s) usually sound much much more formal with a very formal english. And i can't seem to be able to stop it from being overly helpful, even with few example prompts given, it does improve much more(few shot learning) but not for all types of question(s) or all type of framing i expect it to handle. I think it cannot be tuned very much, if i was to give an analogy, i need tuning in scale of milimeter and mistral works in realm of centimeter(s), either over or under following the instruction(s).\n",
        "\n",
        "Though one place where it did worked phenomenal was when user were to share his/her story instead of asking question directly, maybe because user isn't able to pin point as to what exactly is it that they need to ask. It was good at summarizing the story to a sentance or two which can be relatively easily searched in faiss with decent score.\n"
      ],
      "metadata": {
        "id": "Um6K5HFWh81W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import IntEnum\n",
        "\n",
        "class Document(IntEnum):\n",
        "    BNS = 0\n",
        "    APEX = 1\n",
        "    HIGH = 2\n",
        "    ALL = 3\n",
        "\n",
        "index_map = {\n",
        "    Document.BNS: index_bns,\n",
        "    Document.APEX: index_apex,\n",
        "    Document.HIGH: index_high,\n",
        "}"
      ],
      "metadata": {
        "id": "ywbEL0uXyWQc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def faiss_search(query, model, document, metadata, top_k=2):\n",
        "    '''\n",
        "    apex high or bns in document argument to search only one of them\n",
        "    '''\n",
        "    if isinstance(query, str):\n",
        "        query = [query] # we need list for faiss\n",
        "\n",
        "    query_encoded = model.encode(query, normalize_embeddings=True, convert_to_numpy=True)\n",
        "\n",
        "    documents_retrieved = []\n",
        "    similarity_scores = []\n",
        "\n",
        "    retrieved_similarity, retrieved_document = index_map[document].search(query_encoded, top_k)\n",
        "    for q in range(len(query)):\n",
        "        for k in range(top_k):\n",
        "            similarity_scores.append(retrieved_similarity[q][k])\n",
        "            documents_retrieved.append(f'''\n",
        "                confidence : {retrieved_similarity[q][k]},\n",
        "                source : {metadata[document][retrieved_document[q][k]]['source']},\n",
        "                doc : {metadata[document][retrieved_document[q][k]]['chunk_text']}\n",
        "            ''')\n",
        "    return documents_retrieved, similarity_scores\n",
        "\n",
        "def faiss_search_all(query, model, metadata, top_k=2):\n",
        "    if isinstance(query, str):\n",
        "        query = [query]\n",
        "    query_encoded = model.encode(query, normalize_embeddings=True, convert_to_numpy=True)\n",
        "    documents = []\n",
        "    similarity = []\n",
        "\n",
        "    for bases in Document:\n",
        "        if bases == Document.ALL:\n",
        "            continue\n",
        "        sim, doc = index_map[bases].search(query_encoded, top_k)\n",
        "        for q in range(len(query)):\n",
        "            for k in range(top_k):\n",
        "                similarity.append(sim[q][k])\n",
        "                documents.append(f'''\n",
        "                    confidence : {sim[q][k]},\n",
        "                    source : {metadata[bases][doc[q][k]]['source']},\n",
        "                    doc : {metadata[bases][doc[q][k]]['chunk_text']}\n",
        "                ''')\n",
        "    return documents, similarity\n",
        "\n",
        "def faiss_search_all_top(query, model, metadata, top):\n",
        "    # faisss_search_all but return top k matches\n",
        "    documents, similarity = faiss_search_all(query, model, metadata, top)\n",
        "\n",
        "    return sorted(zip(documents, similarity), reverse=True, key = lambda x : x[1])[:top]\n",
        "\n",
        "question = \"Can i take duck from local pond?\"\n",
        "\n",
        "print(faiss_search(question, model_faiss, Document.APEX, metadata, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CJfXh2Blk-z",
        "outputId": "1a42885a-c822-4f8a-dfc9-a67b2841f025",
        "collapsed": true
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([\"\\n                confidence : 0.4602753221988678,\\n                source : Supreme Court,\\n                doc : The State including Respondents 11 to 13 shall restore the pond, develop and maintain the same as a recreational spot which will undoubtedly be in the best interest of the villagers.\\nFurther it will also help in maintaining ecological balance and protecting the environment in regard to which this Court has repeatedly expressed its concern.\\nSuch measures must begin at the grass-root level if they were to become the nation's pride. The appeal is accordingly allowed.\\nThere shall be no order as to costs.\\n            \"], [np.float32(0.46027532)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below defines some prompt(s) which intend to serve different purposes according to need of user. And several combination(s) of prompts are then encapsulated as function(s) of different name(s) to be called for convinience."
      ],
      "metadata": {
        "id": "MXgTNaidkjH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = \"\"\n",
        "prompt_reply_with_docs =  \"\"\"<s>[INST]\n",
        "You are a user-facing chat model working in a law firm.\n",
        "You are given:\n",
        "- A user question\n",
        "- A set of document snippets retrieved from a legal database, each with a relevance score\n",
        "Your task is to answer the user’s question using ONLY the information contained in the provided document snippets.\n",
        "\n",
        "Rules:\n",
        "- Use only facts, principles, or reasoning explicitly present in the provided snippets\n",
        "- Do NOT rely on general legal knowledge or assumptions outside the documents\n",
        "- Do NOT infer or reconstruct missing parts of documents\n",
        "- If the provided documents do not directly address the legal issue raised in the question, apologize briefly and refuse to answer\n",
        "- Do NOT mention the number of documents used\n",
        "- Do NOT mention retrieval, embeddings, or confidence scores\n",
        "\n",
        "Your reply must be:\n",
        "- Concise\n",
        "- Easy to understand for a casual user with no legal background\n",
        "- Directly grounded in the provided documents\n",
        "\n",
        "Question:\n",
        "{user_question}\n",
        "\n",
        "Documents:\n",
        "{documents}\n",
        "[/INST]\"\"\".format(user_question = question, documents = documents)\n",
        "\n",
        "prompt_reply_rephrased = \"\"\"<s>[INST]\n",
        "You are a query rewriting engine for a Retrieval-Augmented Generation (RAG) system.\n",
        "\n",
        "Your job:\n",
        "- Rewrite the user's question into a concise, factual, search-oriented query\n",
        "- Remove conversational language, opinions, and filler\n",
        "- Preserve legal / technical terminology\n",
        "- Do NOT answer the question\n",
        "- Do NOT add new information\n",
        "- Output ONLY the rewritten query\n",
        "\n",
        "Think like a search engine, not a chatbot.\n",
        "\n",
        "Question:\n",
        "{user_question}\n",
        "\n",
        "[/INST]\"\"\".format(user_question = question)"
      ],
      "metadata": {
        "id": "RzYet_UXlI69"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply = \"\"\n",
        "documents = faiss_search(reply, model_faiss, Document.HIGH, metadata, 2)\n",
        "prompt = \"\"\"<s>[INST]\n",
        "You are a user-facing chat model working in a law firm.\n",
        "You are given:\n",
        "- A user question\n",
        "- A set of document snippets retrieved from a legal database, each with a relevance score\n",
        "Your task is to answer the user’s question using ONLY the information contained in the provided document snippets.\n",
        "\n",
        "Rules:\n",
        "- Use only facts, principles, or reasoning explicitly present in the provided snippets\n",
        "- Do NOT rely on general legal knowledge or assumptions outside the documents\n",
        "- Do NOT infer or reconstruct missing parts of documents\n",
        "- If the provided documents do not directly address the legal issue raised in the question, apologize briefly and refuse to answer\n",
        "- Do NOT mention anything about existance of documents in your reply\n",
        "- Do NOT mention retrieval, embeddings, or confidence scores\n",
        "\n",
        "Your reply must be:\n",
        "- Concise\n",
        "- Easy to understand for a casual user with no legal background\n",
        "- Directly grounded in the provided documents\n",
        "\n",
        "Question:\n",
        "{user_question}\n",
        "\n",
        "Documents:\n",
        "{documents}\n",
        "[/INST]\"\"\".format(user_question = question, documents = documents)\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=300,\n",
        "        do_sample=False\n",
        "    )\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "MrxivmvelnyN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_model(question):\n",
        "    prompt = f\"{question}\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=300,\n",
        "            do_sample=False\n",
        "        )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "def ask_with_retrieval(question, document=Document.APEX, top_k=2, cutoff_score=0.0, show_docs=False):\n",
        "    \"\"\"\n",
        "    cutoff_score will later need to be passed to faiss search function :: TODO\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "\n",
        "    if document == Document.ALL:\n",
        "        documents, _ = faiss_search_all(question, model_faiss, metadata, top_k)\n",
        "    else:\n",
        "        documents, _ = faiss_search(question, model_faiss, document, metadata, top_k)\n",
        "\n",
        "    if show_docs:\n",
        "        for entries in documents:\n",
        "            print(entries)\n",
        "\n",
        "    prompt = prompt_reply_with_docs.format(user_question = question, documents = documents)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=300,\n",
        "            do_sample=False\n",
        "        )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "def ask_with_rephrasing(question, document=Document.APEX,top_k=2, cutoff_score=0.45, show_docs=False, compare=False):\n",
        "    documents = []\n",
        "    raw_scores = []\n",
        "    if document == Document.ALL:\n",
        "        documents, raw_scores = faiss_search_all(question, model_faiss, metadata, top_k)\n",
        "    else:\n",
        "        documents, raw_scores = faiss_search(question, model_faiss, document, metadata, top_k)\n",
        "\n",
        "    query = prompt_reply_rephrased.format(user_question = question)\n",
        "    inputs_1 = tokenizer(query, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        output_1 = model.generate(\n",
        "            **inputs_1,\n",
        "            max_new_tokens=300,\n",
        "            do_sample=False\n",
        "        )\n",
        "    rephrased_query = tokenizer.decode(output_1[0], skip_special_tokens=True)\n",
        "    retrieval = []\n",
        "    scores = []\n",
        "    if document == Document.ALL:\n",
        "        retrieval, scores = faiss_search_all(rephrased_query, model_faiss, metadata, top_k)\n",
        "    else:\n",
        "        retrieval, scores = faiss_search(rephrased_query, model_faiss, document, metadata, top_k)\n",
        "    if show_docs:\n",
        "        for doc in retrieval:\n",
        "            print(doc)\n",
        "    if compare:\n",
        "        print(f\"scores of docs fetched by user query on faiss :: {raw_scores}\")\n",
        "        print(f\"scores of docs fetched after rewriting by model :: {scores}\")\n",
        "\n",
        "    prompt = prompt_reply_with_docs.format(user_question = rephrased_query, documents = retrieval)\n",
        "    inputs_2 = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        output_2 = model.generate(\n",
        "            **inputs_2,\n",
        "            max_new_tokens=300,\n",
        "            do_sample=False\n",
        "        )\n",
        "    return tokenizer.decode(output_2[0], skip_special_tokens=True)\n",
        "\n",
        "def get_full_document(id):\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "k9v8wfoClZMZ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ask_with_rephrasing(question, Document.ALL, 2, 0.34, False, True)\n",
        "\n"
      ],
      "metadata": {
        "id": "l3T208L43kek"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}